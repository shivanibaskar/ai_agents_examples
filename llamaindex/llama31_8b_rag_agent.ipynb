{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3.1 Rag Agent with LlamaIndex\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ytang07/ai_agents_cookbooks/blob/main/llamaindex/llama31_8b_rag_agent.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook will walk you through building a LlamaIndex ReactAgent using Llama 3.1 70b. We will be using [OctoAI](https://octo.ai) as our embeddings and llm provider.\n",
    "\n",
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -qU llama-index llama-index-llms-openai llama-index-readers-file octoai llama-index-llms-octoai llama-index-embeddings-octoai llama-index-embeddings-openai llama-index-llms-openai-like\n",
    "\n",
    "# ! pip freeze | grep llama-index-core\n",
    "# ! pip freeze | grep embeddings-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API Keys\n",
    "To run the rest of the notebook you will need access to an OctoAI API key. You can sign up for an account [here](https://octoai.cloud/). If you need further guidance you can check OctoAI's [documentation page](https://octo.ai/docs/getting-started/how-to-create-octoai-access-token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from getpass import getpass\n",
    "# environ[\"OCTOAI_API_KEY\"] = getpass(\"Input your OCTOAI API key: \")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OCTOAI_API_KEY = environ[\"OCTOAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and setup LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujian/Documents/workspace/ai_agents_cookbooks/p312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.embeddings.octoai import OctoAIEmbedding\n",
    "from llama_index.core import Settings as LlamaGlobalSettings\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "# Set the default model to use for embeddings\n",
    "LlamaGlobalSettings.embed_model = OctoAIEmbedding()\n",
    "\n",
    "# Create an llm object to use for the QueryEngine and the ReActAgent\n",
    "llm = OpenAILike(\n",
    "    model=\"meta-llama-3.1-70b-instruct\",\n",
    "    api_base=\"https://text.octoai.run/v1\",\n",
    "    api_key=environ[\"OCTOAI_API_KEY\"],\n",
    "    context_window=40000,\n",
    "    is_function_calling_model=True,\n",
    "    is_chat_model=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the point we create our vector indexes, by calculating the embedding vectors for each of the chunks. You only need to run this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 238/238 [00:00<00:00, 870.97it/s]\n",
      "Generating embeddings: 100%|██████████| 343/343 [00:07<00:00, 48.54it/s]\n"
     ]
    }
   ],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs, show_progress=True)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs, swow_progress=True)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the query engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now define the query engines as tools that will be used by the agent.\n",
    "\n",
    "As there is a query engine per document we need to also define one tool for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Agent\n",
    "Now we have all the elements to create a LlamaIndex ReactAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_turns=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can interact with the agent and ask a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8a161782-2ffa-4d8f-bd9f-03972648fefe. Step input: Which got the most revenue growth in 2021, Lyft or Uber?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question. I will first find the revenue growth of Lyft in 2021.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"What was Lyft's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The provided context does not explicitly state Lyft's revenue growth in 2021. However, it mentions that revenue in 2020 was higher in the first quarter of 2020 prior to the implementation of shelter-in-place orders and other travel restrictions across North America beginning March 2020. It also mentions that the company expects to see continued recovery in demand for its platform and the resulting positive impacts on revenue as there are more widespread immunity levels, more communities reopen, and other restrictive travel and social distancing measures in response to COVID-19 are eased.\n",
      "\u001b[0m> Running step f30839ad-1b99-4630-816b-557a032cd6bc. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The provided context does not explicitly state Lyft's revenue growth in 2021. I will try to find the revenue of Lyft in 2021.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"What was Lyft's revenue in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: $3,208,323\n",
      "\u001b[0m> Running step 9d0384c0-c516-40cd-b020-554bc894182f. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The revenue of Lyft in 2021 is $3,208,323. Now, I need to find the revenue of Lyft in 2020 to calculate the revenue growth.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"What was Lyft's revenue in 2020?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: $2,364,681\n",
      "\u001b[0m> Running step ac92fb4e-39d8-4ff0-87aa-21300ccb6c4d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The revenue of Lyft in 2020 is $2,364,681. Now, I can calculate the revenue growth of Lyft in 2021, which is ($3,208,323 - $2,364,681) / $2,364,681 = 35.8%. Next, I will find the revenue growth of Uber in 2021.\n",
      "Action: uber_10k\n",
      "Action Input: {'input': \"What was Uber's revenue growth in 2021?\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Uber's revenue increased by $6.3 billion, or 57%, in 2021 compared to 2020.\n",
      "\u001b[0m> Running step 49677f96-7a61-4895-a14a-8837441ab53d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The revenue growth of Uber in 2021 is 57%, which is higher than Lyft's revenue growth of 35.8%. Now, I can answer the question.\n",
      "Answer: Uber got the most revenue growth in 2021, with a 57% increase compared to Lyft's 35.8% increase.\n",
      "\u001b[0mUber got the most revenue growth in 2021, with a 57% increase compared to Lyft's 35.8% increase.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Which got the most revenue growth in 2021, Lyft or Uber?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aacb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
