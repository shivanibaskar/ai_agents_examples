{"docstore/metadata": {"2ad58b7e-c45a-4a97-bc42-d8c64b677588": {"doc_hash": "0f14b6f8ac67d932a66023b2dbb57476ae35928838fbed04e64e09c02df4bd70"}, "4cb57e55-1f34-4c0d-9677-906c990bb9cd": {"doc_hash": "9bcaf1512e9a2ce468e0503994e6b756318b440b73813e2881a4faa125731dd6", "ref_doc_id": "2ad58b7e-c45a-4a97-bc42-d8c64b677588"}, "11776c9e-2edf-438e-af0c-b488e3d61e54": {"doc_hash": "192193432efaf69d3a174cdfa0cac78ecc4cfb67f776c0245728e37ad3696886", "ref_doc_id": "2ad58b7e-c45a-4a97-bc42-d8c64b677588"}}, "docstore/data": {"4cb57e55-1f34-4c0d-9677-906c990bb9cd": {"__data__": {"id_": "4cb57e55-1f34-4c0d-9677-906c990bb9cd", "embedding": null, "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ad58b7e-c45a-4a97-bc42-d8c64b677588", "node_type": "4", "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "0f14b6f8ac67d932a66023b2dbb57476ae35928838fbed04e64e09c02df4bd70", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "11776c9e-2edf-438e-af0c-b488e3d61e54", "node_type": "1", "metadata": {}, "hash": "7dcbca2770e7c3412223f1644d3e502cfdff7736ea2f322dc2d77f184539b66e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Why AI Engineers Need a Unified Tool for AI Evaluation and Observability\n\nURL Source: http://arize.com/blog/why-ai-engineers-need-a-unified-tool-for-ai-evaluation-and-observability/\n\nPublished Time: 2025-02-28T22:23:13+00:00\n\nMarkdown Content:\nAI engineers today face a growing challenge: bridging the gap between development and production while ensuring high performance across diverse AI model types\u2014whether it\u2019s generative AI, traditional machine learning (ML), or computer vision (CV).\n\nTraditionally, development and production have been treated as separate phases, but in reality, they are deeply interconnected:\n\n*   Development informs production by ensuring robust experimentation and evaluation before deployment.\n*   Production fuels iterative development by surfacing real-world feedback, errors, and performance regressions that guide model improvements.\n\nAI teams need a single platform that unifies these two phases, allowing them to seamlessly develop, evaluate, monitor, and iterate\u2014without silos or blind spots.\n\nThis is where Arize\u2019s unified AI observability and evaluation platform comes in. Built specifically for AI engineers, Arize provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types, enabling teams to:\n\n*   Develop with confidence by testing and benchmarking performance before launch.\n*   Monitor and debug production applications with streamlined workflows.\n*   Use online production data for continuous experimentation and iterative development.\n\nBy connecting development and production in a single feedback loop, Arize ensures that AI engineers can iterate faster and deploy AI applications with confidence.\n\n![Image 1: Building and Evaluating Next-Gen AI Blog inline image graphic](https://arize.com/wp-content/uploads/2025/02/Building-and-Evaluating-Next-Gen-AI-Promo-Blog-inline-image-1024x450.jpg)\n\nThe AI Development-Production Feedback Loop\n-------------------------------------------\n\nArize is designed to break down the barriers between development and production, creating a continuous improvement cycle:\n\n### (1) Development Informs Production\n\n*   Run experiments, and compare results, to test your evaluation metrics, prompts, models, and more, so you can deploy with confidence.\n*   Define evaluation benchmarks and standardize frameworks for both offline and online evaluation, ensuring consistency across development and production.\n*   Curate datasets and organize traces and spans from development data, human annotations, or uploaded CSVs to ensure that application changes don\u2019t trigger unintended cascading effects.\n*   Trace your application and get full visibility into your application for debugging function calls, poor retrieval, hallucinations, latency, and more before real-world users interact with your application.\n\n![Image 2: Demo model manager](https://arize.com/wp-content/uploads/2025/02/image4-1-1024x553.png)\n\n### (2) Production Fuels Iterative Development\n\n*   With end-to-end observability across every step of your AI application or model, gain a comprehensive view of user interactions, automatically detect failure cases, and pinpoint performance issues that need attention.\n*   Use LLM evaluations and guardrails to detect hallucinations, agentic failures, and unexpected regressions early, preventing issues before they impact users.\n*   Identify and curate production insights using AI Search and Annotations, seamlessly feeding them into Datasets and Experiments to drive continuous improvement and refinement.\n\n![Image 3: Search Router - Chat companion screenshot](https://arize.com/wp-content/uploads/2025/02/image2-2-1024x552.png)\n\n### (3) Continuous Improvement & Deployment\n\n*   Fine-tune models based on production feedback by curating data into Datasets, with the ability to export refined data for retraining and continuous improvement.\n*   Test and refine evaluations and prompts using Prompt Playground, leveraging real-world inputs to optimize performance. Store all versions in Prompt Hub and Eval Hub for seamless access, comparison, and iteration.\n\n![Image 4: Search Router - Chat companion screenshot](https://arize.com/wp-content/uploads/2025/02/image3-2-1024x551.png)\n\nOne Unified Platform Across Your AI Portfolio\n---------------------------------------------\n\nArize supports the full spectrum of AI-powered systems and applications, whether you\u2019re working with:\n\n### GenAI\n\n*   Debug function calling, RAG, and multi-modal applications.\n*   Detect hallucinations and toxicity, accuracy, and coherence.\n*   Run self-improving evaluations and prompts.\n\n### Computer Vision (CV)\n\n*   Track drift in embeddings, object detection, and segmentation models.\n*   Surface edge-case failures across real-world datasets.\n*   Debug CV pipelines with frame-by-frame analysis.\n\n### Machine Learning (ML)\n\n*   Monitor tabular, time-series, and recommendation models at scale.\n*   Detect data drift, feature importance shifts, and model decay.\n*   Automatically curate datasets for retraining based on production issues.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5060, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "11776c9e-2edf-438e-af0c-b488e3d61e54": {"__data__": {"id_": "11776c9e-2edf-438e-af0c-b488e3d61e54", "embedding": null, "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ad58b7e-c45a-4a97-bc42-d8c64b677588", "node_type": "4", "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "0f14b6f8ac67d932a66023b2dbb57476ae35928838fbed04e64e09c02df4bd70", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4cb57e55-1f34-4c0d-9677-906c990bb9cd", "node_type": "1", "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "9bcaf1512e9a2ce468e0503994e6b756318b440b73813e2881a4faa125731dd6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "![Image 4: Search Router - Chat companion screenshot](https://arize.com/wp-content/uploads/2025/02/image3-2-1024x551.png)\n\nOne Unified Platform Across Your AI Portfolio\n---------------------------------------------\n\nArize supports the full spectrum of AI-powered systems and applications, whether you\u2019re working with:\n\n### GenAI\n\n*   Debug function calling, RAG, and multi-modal applications.\n*   Detect hallucinations and toxicity, accuracy, and coherence.\n*   Run self-improving evaluations and prompts.\n\n### Computer Vision (CV)\n\n*   Track drift in embeddings, object detection, and segmentation models.\n*   Surface edge-case failures across real-world datasets.\n*   Debug CV pipelines with frame-by-frame analysis.\n\n### Machine Learning (ML)\n\n*   Monitor tabular, time-series, and recommendation models at scale.\n*   Detect data drift, feature importance shifts, and model decay.\n*   Automatically curate datasets for retraining based on production issues.\n\nInstead of siloed tools for each model type, Arize provides a single pane of glass to monitor, evaluate, and iterate across LLMs, CV, and ML models alike.\n\nWhy AI Engineers Choose Arize AI\n--------------------------------\n\n*   **One platform from dev to prod** \u2013 No more disconnected workflows.\n*   **Enterprise-scale deployments** \u2013 Trusted by leading AI teams.\n*   **AI-powered workflows** \u2013 Automated debugging & insights.\n*   **Open-source & open standards** \u2013 Built on OpenTelemetry & OSS evals.\n\nIn a world where AI applications are constantly evolving, Arize ensures that every production insight fuels better development\u2014and every update leads to stronger performance in production.\n\n[Sign up](https://app.arize.com/auth/join) to explore Arize today or [book a demo](https://arize.com/request-a-demo/) to learn more about how Arize works for your specific AI use case.", "mimetype": "text/plain", "start_char_idx": 4100, "end_char_idx": 5938, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"2ad58b7e-c45a-4a97-bc42-d8c64b677588": {"node_ids": ["4cb57e55-1f34-4c0d-9677-906c990bb9cd", "11776c9e-2edf-438e-af0c-b488e3d61e54"], "metadata": {"file_path": "arize_blogs/unified_tool_for_evalution_and_observability.md", "file_name": "unified_tool_for_evalution_and_observability.md", "file_type": "text/markdown", "file_size": 5960, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}}}}