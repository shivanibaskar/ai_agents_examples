{"docstore/metadata": {"97d774e1-b508-4bc0-911f-66ad14ba3308": {"doc_hash": "39aee4f6c2b6bcbe4fcf77f4f3f4fa6f2ec491d4dd72e57cf54ad9be02897e30"}, "744c52a6-ac38-49a4-87ec-7810ccf3b8f5": {"doc_hash": "3f3bf488059c3cc499773858ff472ee0d8d00c9c31d649bcf09d09e07b197973", "ref_doc_id": "97d774e1-b508-4bc0-911f-66ad14ba3308"}, "19cddb7f-6331-496b-8dc3-cbe577ed345c": {"doc_hash": "87c0abbab624652503cd14625b7de2dee1195291d1e76376af72c1ac8f40fc98", "ref_doc_id": "97d774e1-b508-4bc0-911f-66ad14ba3308"}}, "docstore/data": {"744c52a6-ac38-49a4-87ec-7810ccf3b8f5": {"__data__": {"id_": "744c52a6-ac38-49a4-87ec-7810ccf3b8f5", "embedding": null, "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "97d774e1-b508-4bc0-911f-66ad14ba3308", "node_type": "4", "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "39aee4f6c2b6bcbe4fcf77f4f3f4fa6f2ec491d4dd72e57cf54ad9be02897e30", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "19cddb7f-6331-496b-8dc3-cbe577ed345c", "node_type": "1", "metadata": {}, "hash": "39dcf3acf7538804e804163e8a742b929e7ba8caa558f31340d36f177b4a2410", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: How We Scaled Support in Arize Copilot Without Slowing Down\n\nURL Source: http://arize.com/blog/how-we-scaled-support-in-arize-copilot-without-slowing-down/\n\nPublished Time: 2025-03-05T20:24:59+00:00\n\nMarkdown Content:\nArize Copilot has always had a clear vision: to empower AI engineers and data scientists to spend less time on repetitive tasks and more time building innovative applications. Copilot streamlines workflows, automates debugging, and surfaces actionable insights\u2014all designed to help users move faster and achieve more.\n\nWith [Copilot](https://arize.com/blog/introducing-arize-ai-copilot/), we\u2019ve always prioritized putting its capabilities where users need them most. From our experience, it\u2019s clear that great AI applications can expand beyond chat, so while the chat window was our starting point, it quickly became clear that not all interactions fit into this format. With each new skill, we\u2019ve moved further away from relying exclusively on chat and focused on embedding Copilot directly into the workflows it supports.\n\nIn this blog, we\u2019ll share how strategic decisions allowed us to scale Copilot\u2019s capabilities efficiently, including how [partnering with an AI-powered support solution](https://www.runllm.com/product) helped us quickly enhance technical support without pulling engineers away from core development.\n\nInnovating with Our Expertise\n-----------------------------\n\nWith just two people dedicated to the project, we had to prioritize skills that were the best aligned with our expertise and that delivered the most value with the least lift.\n\nTake our filter tool suite as an example. This skill integrates seamlessly into the filter bar, allowing users to interact with Copilot using natural language while staying within the context of their task. It doesn\u2019t pull them out of their flow but instead meets them exactly where they need it. On the other hand, some skills\u2014like our support skill\u2014make perfect sense in the main chat window. Users might need help anywhere in the platform, so the chat is always available across every page. Here, users can ask questions, follow up as needed, and easily pick up where they left off.\n\nUltimately, our goal is to create purposeful integrations that enhance the user experience. Whether it\u2019s a tool embedded in a specific workflow or a universally accessible chat, every Copilot skill is designed to fit naturally into how our users work.\n\nMaking Strategic Decisions to Stay Focused\n------------------------------------------\n\nWhile some features were achievable through prompt engineering and internal APIs, others\u2014like technical support\u2014required more than we could manage on our own. Early on, we knew that technical support would be a critical skill for Copilot. Our platform is highly technical, and new users often need guidance to make the most of it. Without fast, accurate answers, they could lose momentum\u2014or worse, churn.\n\nHowever, building an AI-powered support system from scratch would have required weeks of development time, pulling our engineers away from Copilot\u2019s core capabilities. This led us to partner with [RunLLM](https://runllm.com/), an AI-powered technical support solution designed to handle complex user queries with precision.\n\nFrom the very first test, RunLLM impressed us. We tested their assistant by having it write a GQL query for one of our monitors\u2014a real use case\u2014and it delivered the correct answer faster than expected. Within an hour of exploring their documentation, we had a fully functioning technical support skill integrated into Copilot. What would have taken over a month to build in-house was live in a matter of hours.\n\nDelivering Impact with Copilot\n------------------------------\n\nCopilot adoption has been steadily growing, with sustained engagement and clear usage trends over the past several months. We\u2019ve seen consistent increases in requests, with notable spikes in November and January, signaling that users are actively finding value in Copilot\u2019s AI-powered assistance. While there are natural fluctuations, our most-used skills\u2014Arize Support and Filter with AI\u2014continue to drive engagement and deliver impact.\n\n![Image 1: Graph showing number of copilot requests](https://arize.com/wp-content/uploads/2025/03/image1-1-1024x230.png)\n\nNumber of Copilot requests\n\n![Image 2: Graph showing usage by skill](https://arize.com/wp-content/uploads/2025/03/image2-1024x290.png)\n\nUsage by skill\n\nAt the same time, we recognize there\u2019s still room to grow. In the last six months, we\u2019ve had around 700 unique users, and we\u2019re focused on accelerating adoption by improving the UX, making Copilot more accessible in key workflows, and expanding its capabilities based on customer feedback.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4723, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "19cddb7f-6331-496b-8dc3-cbe577ed345c": {"__data__": {"id_": "19cddb7f-6331-496b-8dc3-cbe577ed345c", "embedding": null, "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "97d774e1-b508-4bc0-911f-66ad14ba3308", "node_type": "4", "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "39aee4f6c2b6bcbe4fcf77f4f3f4fa6f2ec491d4dd72e57cf54ad9be02897e30", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "744c52a6-ac38-49a4-87ec-7810ccf3b8f5", "node_type": "1", "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "3f3bf488059c3cc499773858ff472ee0d8d00c9c31d649bcf09d09e07b197973", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "While there are natural fluctuations, our most-used skills\u2014Arize Support and Filter with AI\u2014continue to drive engagement and deliver impact.\n\n![Image 1: Graph showing number of copilot requests](https://arize.com/wp-content/uploads/2025/03/image1-1-1024x230.png)\n\nNumber of Copilot requests\n\n![Image 2: Graph showing usage by skill](https://arize.com/wp-content/uploads/2025/03/image2-1024x290.png)\n\nUsage by skill\n\nAt the same time, we recognize there\u2019s still room to grow. In the last six months, we\u2019ve had around 700 unique users, and we\u2019re focused on accelerating adoption by improving the UX, making Copilot more accessible in key workflows, and expanding its capabilities based on customer feedback. With new skills, deeper integrations, and a sharper focus on usability, we\u2019re ensuring Copilot meets users where they need it most\u2014helping them get to insights faster and more efficiently.\n\nLooking Ahead\n-------------\n\nThe AI landscape is changing faster than any of us can keep up with, but that\u2019s part of our job at Arize. We\u2019re constantly asking ourselves how to make AI engineers more productive and how we can automate away more tedious tasks. Part of that is knowing where to keep our focus \u2013 by choosing to partner strategically with a product like RunLLM, we delivered a high-quality product to our customers faster than we would have otherwise. That\u2019s unlocked our time to work on key new features, and our roadmap is exciting: automatic debugging, deep insights, and tracing are all in the works. Stay tuned!\n\n[More details on RunLLM\u2019s blog](https://www.runllm.com/blog/how-arize-ai-transformed-technical-support-with-runllm).", "mimetype": "text/plain", "start_char_idx": 4018, "end_char_idx": 5660, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"97d774e1-b508-4bc0-911f-66ad14ba3308": {"node_ids": ["744c52a6-ac38-49a4-87ec-7810ccf3b8f5", "19cddb7f-6331-496b-8dc3-cbe577ed345c"], "metadata": {"file_path": "arize_blogs/how_we_scaled_support_without_slowing_down.md", "file_name": "how_we_scaled_support_without_slowing_down.md", "file_type": "text/markdown", "file_size": 5720, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}}}}