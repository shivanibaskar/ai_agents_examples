{"docstore/metadata": {"b351fbc2-2ba5-4387-995e-f168b8ac75d5": {"doc_hash": "2bfbcffe5aeb59ad09d0f99d79f2e4da3d1b643411248ddf0cc4202c3b55c179"}, "e85cfb81-8820-4b69-b0c9-1f73cc9711cb": {"doc_hash": "4ccf8c8641a2e437b1bb7d3852b3501259420e8dba06c2aac8449265f3ac8074", "ref_doc_id": "b351fbc2-2ba5-4387-995e-f168b8ac75d5"}, "1c3a6bda-163a-4e4e-aaad-51d9edf208e0": {"doc_hash": "b05c1bda0f867f250baacfb16c7e5f669fe9503345448c30552c0aa1cb433c89", "ref_doc_id": "b351fbc2-2ba5-4387-995e-f168b8ac75d5"}}, "docstore/data": {"e85cfb81-8820-4b69-b0c9-1f73cc9711cb": {"__data__": {"id_": "e85cfb81-8820-4b69-b0c9-1f73cc9711cb", "embedding": null, "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b351fbc2-2ba5-4387-995e-f168b8ac75d5", "node_type": "4", "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "2bfbcffe5aeb59ad09d0f99d79f2e4da3d1b643411248ddf0cc4202c3b55c179", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "1c3a6bda-163a-4e4e-aaad-51d9edf208e0", "node_type": "1", "metadata": {}, "hash": "455adcd4b3bc674f1ca279a5b54833ed7367498fe49e042196ed730e84768d56", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Title: Understanding Agentic RAG\n\nURL Source: http://arize.com/blog/understanding-agentic-rag/\n\nPublished Time: 2025-02-05T17:38:53+00:00\n\nMarkdown Content:\nRetrieval-Augmented Generation (RAG) has become a cornerstone in AI applications, and as our needs grow, more complex, traditional RAG approaches are showing their limitations. Enter Agentic RAG, which introduces intelligent agents into the retrieval process.\n\nLet\u2019s talk about what it is, how it works, and why monitoring and observability are key parts of the process.\n\nTutorial: Trace an Agentic RAG App\n----------------------------------\n\nThis companion notebook will help you build and trace an agentic RAG system using LlamaIndex\u2019s ReAct agent framework combined with vector and SQL query tools, and Arize Phoenix. [Go to the notebook.](https://github.com/Arize-ai/phoenix/blob/main/tutorials/tracing/agentic_rag_tracing.ipynb)\n\nWatch: Agentic RAG Overview\n---------------------------\n\nRAG: A Quick Recap\n------------------\n\nLet\u2019s start with a quick refresh on traditional RAG, which is kind of like a librarian finding the perfect book for you.\n\nRAG implements a vector-based retrieval process that begins with the transformation of documents into dense vector embeddings. These are then indexed in a vector store. When processing a user query, the system computes an embedding for the input and performs semantic similarity computations (typically using cosine similarity metrics) against the stored document embeddings.\n\nThe highest-scoring documents are then retrieved and concatenated into the context window of the prompt, providing the foundation for the language model\u2019s response generation. While this architecture has proven effective for straightforward retrieval tasks, it presents limitations when dealing with heterogeneous data sources or complex, multi-step queries that require more nuanced retrieval strategies. You can read about tracing and evaluating RAG [in our docs here.](https://docs.arize.com/arize/examples/trace-and-evaluate-rag)\n\nWhile this approach works well for simple use cases, it faces challenges when dealing with multiple data sources or complex queries.\n\nAgentic RAG: Adding Intelligence to Retrieval\n---------------------------------------------\n\nAgentic RAG introduces AI agents into the retrieval process, acting as intelligent intermediaries between user queries and data sources.\n\nThese agents can:\n\n*   Determine if external knowledge sources are needed at all\n*   Choose which specific data sources to query based on the question\n*   Evaluate if the retrieved context actually helps answer the user\u2019s question  \n    Decide whether to try alternative retrieval strategies if initial results are inadequate\n\nSingle vs. Multi-Agent RAG\n--------------------------\n\nAgentic RAG can be implemented in two ways:\n\n**Single Agent:** One agent manages all retrieval operations and decision-making processes.\n\n**Multi-Agent:** Multiple specialized agents handle different aspects of retrieval:\n\n*   One agent for internal knowledge base queries\n*   Another agent for external API calls\n*   Additional agents for specialized tools and operations\n\nPractical Implementation: A Real-World Example\n----------------------------------------------\n\nLet\u2019s look at a practical implementation of Agentic RAG using LlamaIndex. Consider an internal company system that needs to handle both employee information and company policies.\n\n### Architecture Components\n\nThe implementation\u2019s foundation rests on a dual-database architecture that leverages both vector and relational paradigms. The system employs Chroma as the vector store for managing company policy documents, while PostgreSQL serves as the relational backbone for structured employee data.\n\nThis data architecture means we need specialized query engines: a natural language SQL query engine interfaces with PostgreSQL, translating semantic queries into structured SQL, while a vector query engine handles document retrieval operations through Chroma.\n\nThe agent layer sits on top of this infrastructure, configured with specific context parameters that define its operational boundaries and decision-making capabilities. The agent\u2019s architecture incorporates detailed tool descriptions that serve as a decision framework for selecting appropriate data sources, complemented by integration with GPT-3.5 Turbo for sophisticated reasoning capabilities. This configuration enables the agent to dynamically select between the vector and relational query engines based on the semantic requirements of incoming queries.\n\n<h2 \u201cMonitoring and Improvement with Observability\u201d\\>Monitoring and Improvement with Observability\n\nOne crucial aspect of implementing Agentic RAG is the ability to monitor and improve its performance. Tools like Arize Phoenix can help by:\n\n*   Tracing query paths and tool selections\n*   Monitoring document retrieval accuracy\n*   Identifying potential improvements in retrieval strategies\n*   Debugging incorrect tool selections or document retrievals\n\nBest Practices and Considerations\n---------------------------------\n\nWhen implementing Agentic RAG, consider these key points:\n\n1.  **Clear Tool Descriptions:** Provide detailed descriptions of each tool\u2019s capabilities to help the agent make informed decisions\n2.  **Robust Testing:** Verify that agents are selecting the correct tools and retrieving appropriate documents\n3.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 5390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1c3a6bda-163a-4e4e-aaad-51d9edf208e0": {"__data__": {"id_": "1c3a6bda-163a-4e4e-aaad-51d9edf208e0", "embedding": null, "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b351fbc2-2ba5-4387-995e-f168b8ac75d5", "node_type": "4", "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "2bfbcffe5aeb59ad09d0f99d79f2e4da3d1b643411248ddf0cc4202c3b55c179", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e85cfb81-8820-4b69-b0c9-1f73cc9711cb", "node_type": "1", "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}, "hash": "4ccf8c8641a2e437b1bb7d3852b3501259420e8dba06c2aac8449265f3ac8074", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This configuration enables the agent to dynamically select between the vector and relational query engines based on the semantic requirements of incoming queries.\n\n<h2 \u201cMonitoring and Improvement with Observability\u201d\\>Monitoring and Improvement with Observability\n\nOne crucial aspect of implementing Agentic RAG is the ability to monitor and improve its performance. Tools like Arize Phoenix can help by:\n\n*   Tracing query paths and tool selections\n*   Monitoring document retrieval accuracy\n*   Identifying potential improvements in retrieval strategies\n*   Debugging incorrect tool selections or document retrievals\n\nBest Practices and Considerations\n---------------------------------\n\nWhen implementing Agentic RAG, consider these key points:\n\n1.  **Clear Tool Descriptions:** Provide detailed descriptions of each tool\u2019s capabilities to help the agent make informed decisions\n2.  **Robust Testing:** Verify that agents are selecting the correct tools and retrieving appropriate documents\n3.  **Document Quality:** Ensure your knowledge base documents contain sufficient context for accurate retrieval\n4.  **Monitoring Strategy:** Implement comprehensive observability to track and improve system performance\n\nAgentic RAG represents a significant advancement in how we approach information retrieval and question-answering systems. By introducing intelligent agents into the retrieval process, we can handle more complex queries across multiple data sources while maintaining accuracy and relevance. The combination of traditional RAG capabilities with agent-based decision-making opens up new possibilities for building more sophisticated AI applications. As this technology continues to evolve, we can expect to see even more innovative implementations and use cases emerge.\n\nGet started in your observability journey with our open source solution [Arize Phoenix](https://phoenix.arize.com/).", "mimetype": "text/plain", "start_char_idx": 4396, "end_char_idx": 6293, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"b351fbc2-2ba5-4387-995e-f168b8ac75d5": {"node_ids": ["e85cfb81-8820-4b69-b0c9-1f73cc9711cb", "1c3a6bda-163a-4e4e-aaad-51d9edf208e0"], "metadata": {"file_path": "arize_blogs/agentic_rag.md", "file_name": "agentic_rag.md", "file_type": "text/markdown", "file_size": 6315, "creation_date": "2025-03-06", "last_modified_date": "2025-03-06"}}}}