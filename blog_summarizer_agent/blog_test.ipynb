{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dotenv) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting phoenix\n",
      "  Downloading phoenix-0.9.1.zip (3.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: phoenix\n",
      "  Building wheel for phoenix (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for phoenix: filename=phoenix-0.9.1-py3-none-any.whl size=4876 sha256=0879555fe5619b1eef55c11f1e8371151dc49ca6e67f7c8ce6c56d334f7dadb3\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/16/0d/f7/42fb504aa607ab96c03deac7280bf369ccfd4b834f476090bf\n",
      "Successfully built phoenix\n",
      "Installing collected packages: phoenix\n",
      "Successfully installed phoenix-0.9.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# dependencies: llama-index llama-index-llms-openai\n",
    "!pip install dotenv\n",
    "!pip install phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "multiple exception types must be parenthesized (__init__.py, line 56)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3549\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport phoenix as px\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/phoenix/__init__.py:56\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexcept PhoenixError, e:\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m multiple exception types must be parenthesized\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openinference'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopeninference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstrumentation\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllama_index\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlamaIndexInstrumentor\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mphoenix\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01motel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register\n\u001b[32m      4\u001b[39m tracer_provider = register()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openinference'"
     ]
    }
   ],
   "source": [
    "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register()\n",
    "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "# Create an llm object to use for the QueryEngine and the ReActAgent\n",
    "llm = OpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agentic_rag.md',\n",
       " 'multiagent_finetuning.md',\n",
       " 'how_we_scaled_support_without_slowing_down.md',\n",
       " 'unified_tool_for_evalution_and_observability.md',\n",
       " 'agent_router_best_practices.md',\n",
       " 'exploring_deepseek.md',\n",
       " 'memory_and_state_in_llm_applications.md',\n",
       " 'how_to_build_an_ai_agent.md']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_docs = os.listdir(\"arize_blogs/\")\n",
    "input_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = {}\n",
    "for doc in input_docs:\n",
    "    data = SimpleDirectoryReader(\n",
    "        input_files=[f\"./arize_blogs/{doc}\"]\n",
    "    ).load_data()\n",
    "    doc_map[doc] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {}\n",
    "for doc in doc_map:\n",
    "    try:\n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            persist_dir=f\"./arize_blog_indexes/{doc}\"\n",
    "        )\n",
    "        vector_index = load_index_from_storage(storage_context)\n",
    "    except:\n",
    "        vector_index = VectorStoreIndex.from_documents(doc_map[doc], show_progress=True)\n",
    "    index_map[doc] = vector_index\n",
    "    vector_index.storage_context.persist(persist_dir=f\"./arize_blog_indexes/{doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "engines = {}\n",
    "for index in index_map:\n",
    "    engines[index] = index_map[index].as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1371d5fd0>,\n",
       " 'multiagent_finetuning.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x135e8e030>,\n",
       " 'how_we_scaled_support_without_slowing_down.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373c9cd0>,\n",
       " 'unified_tool_for_evalution_and_observability.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373bc650>,\n",
       " 'agent_router_best_practices.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373bc050>,\n",
       " 'exploring_deepseek.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d2f30>,\n",
       " 'memory_and_state_in_llm_applications.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d3050>,\n",
       " 'how_to_build_an_ai_agent.md': <llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x1373d2db0>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advancement in AI applications that introduces intelligent agents into the retrieval process, enhancing the handling of complex queries across multiple data sources. It provides a detailed guide on implementing Agentic RAG, emphasizing the importance of clear tool descriptions, robust testing, document quality, and a comprehensive monitoring strategy for system performance.')]), raw=ChatCompletion(id='chatcmpl-BBTyZvVNbsLQ4XwcBTGLSmFOu0KKU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advancement in AI applications that introduces intelligent agents into the retrieval process, enhancing the handling of complex queries across multiple data sources. It provides a detailed guide on implementing Agentic RAG, emphasizing the importance of clear tool descriptions, robust testing, document quality, and a comprehensive monitoring strategy for system performance.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1742076535, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=78, prompt_tokens=1170, total_tokens=1248, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))), delta=None, logprobs=None, additional_kwargs={'prompt_tokens': 1170, 'completion_tokens': 78, 'total_tokens': 1248})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./arize_blogs/agentic_rag.md\", \"r\") as f:\n",
    "    lines = f.read()\n",
    "messages = [\n",
    "    ChatMessage(role=\"system\", content=\"You are a helpful assistant. You describe the information the user provides and summarize it into two concise sentences.\"),\n",
    "    ChatMessage(role=\"user\", content=lines),\n",
    "]\n",
    "response = llm.chat(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The article discusses the concept of Agentic Retrieval-Augmented Generation '\n",
      " '(RAG), an advancement in AI applications that introduces intelligent agents '\n",
      " 'into the retrieval process, enhancing the handling of complex queries across '\n",
      " 'multiple data sources. It provides a detailed guide on implementing Agentic '\n",
      " 'RAG, emphasizing the importance of clear tool descriptions, robust testing, '\n",
      " 'document quality, and a comprehensive monitoring strategy for system '\n",
      " 'performance.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response.message.blocks[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QueryEngineTool(\n",
    "#         query_engine=lyft_engine,\n",
    "#         metadata=ToolMetadata(\n",
    "#             name=\"lyft_10k\",\n",
    "#             description=(\n",
    "#                 \"Provides information about Lyft financials for year 2021. \"\n",
    "#                 \"Use a detailed plain text question as input to the tool.\"\n",
    "#             ),\n",
    "#         ),\n",
    "#     ),\n",
    "\n",
    "tools = []\n",
    "for engine in engines:\n",
    "    with open(f\"./arize_blogs/{engine}\", \"r\") as f:\n",
    "        lines = f.read()\n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", content=\"You are a helpful assistant. You describe the information the user provides and summarize it into two concise sentences.\"),\n",
    "        ChatMessage(role=\"user\", content=lines),\n",
    "    ]\n",
    "    response = llm.chat(messages)\n",
    "    qetool = QueryEngineTool(\n",
    "        query_engine = engines[engine],\n",
    "        metadata=ToolMetadata(\n",
    "            name=engine,\n",
    "            description=(\n",
    "                f\"{response.message.blocks[0].text}.\"\n",
    "                \"Use a detailed plain text question as input to the\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    tools.append(qetool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advanced AI application that introduces intelligent agents into the retrieval process to handle complex queries across multiple data sources. It provides a tutorial on building an Agentic RAG system, discusses its implementation, and emphasizes the importance of monitoring and improving its performance using tools like Arize Phoenix..Use a detailed plain text question as input to the\n",
      "agentic_rag.md\n",
      "The blog post discusses a conversation with Yilun Du, a Senior Research Scientist at Google DeepMind, about his latest research paper on a multiagent finetuning framework that improves the performance and diversity of language models. The framework uses a team of specialized models that learn from each other, maintaining diversity in reasoning and sustaining long-term performance gains, and has potential applications in various reasoning tasks and future advancements in language model development..Use a detailed plain text question as input to the\n",
      "multiagent_finetuning.md\n",
      "Arize Copilot, an AI tool designed to streamline workflows and automate debugging, has scaled its support capabilities without slowing down by strategically partnering with AI-powered support solution, RunLLM. The partnership has allowed Arize to enhance technical support quickly, without diverting engineers from core development, and has resulted in a steady growth in Copilot adoption, with plans for further expansion and integration based on customer feedback..Use a detailed plain text question as input to the\n",
      "how_we_scaled_support_without_slowing_down.md\n",
      "The blog post discusses the need for a unified tool for AI evaluation and observability, highlighting the Arize platform that bridges the gap between development and production phases in AI engineering. Arize provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types, enabling AI teams to develop, monitor, and iterate their applications with confidence, thereby ensuring high performance across diverse AI models..Use a detailed plain text question as input to the\n",
      "unified_tool_for_evalution_and_observability.md\n",
      "The article discusses the importance of an AI agent router in managing user requests and routing them to the correct function within a system, particularly in large-scale conversational systems. It provides an overview of when to implement an agent router, different implementation approaches such as function calling, intent-based routing, and pure code routing, and best practices for agent router implementation including scope management, developing clear guidelines, and performance monitoring..Use a detailed plain text question as input to the\n",
      "agent_router_best_practices.md\n",
      "DeepSeek is developing AI models that push the boundaries of reasoning and reinforcement learning, aiming to train AI to think more like a human. The company's latest models, DeepSeek R.1 and R.1.0, are making significant strides in inference speed and reasoning abilities, with potential applications in enterprise AI, privacy-focused AI, and traditional machine learning tasks..Use a detailed plain text question as input to the\n",
      "exploring_deepseek.md\n",
      "The blog post discusses the concept of memory and state in Language Learning Model (LLM) applications, explaining how different approaches to memory management can impact performance, cost, and user experience. It also provides insights into various state management strategies, the importance of balancing memory usage, and how to choose the best strategy based on specific use cases..Use a detailed plain text question as input to the\n",
      "memory_and_state_in_llm_applications.md\n",
      "The article provides a comprehensive guide on how to build an AI agent using three different frameworks: smolagents, AutoGen, and LangGraph. It explains the concept of an AI agent, when to use one, and how to implement it using these frameworks, with step-by-step instructions and code examples. The article also discusses the advantages and potential drawbacks of using a framework, and when to consider building an agent from scratch..Use a detailed plain text question as input to the\n",
      "how_to_build_an_ai_agent.md\n"
     ]
    }
   ],
   "source": [
    "descriptions = {}\n",
    "for tool in tools:\n",
    "    print(tool.metadata.description)\n",
    "    print(tool.metadata.name)\n",
    "    descriptions[tool.metadata.name] = tool.metadata.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': 'The article discusses the concept of Agentic Retrieval-Augmented Generation (RAG), an advanced AI application that introduces intelligent agents into the retrieval process to handle complex queries across multiple data sources. It provides a tutorial on building an Agentic RAG system, discusses its implementation, and emphasizes the importance of monitoring and improving its performance using tools like Arize Phoenix..Use a detailed plain text question as input to the',\n",
       " 'multiagent_finetuning.md': 'The blog post discusses a conversation with Yilun Du, a Senior Research Scientist at Google DeepMind, about his latest research paper on a multiagent finetuning framework that improves the performance and diversity of language models. The framework uses a team of specialized models that learn from each other, maintaining diversity in reasoning and sustaining long-term performance gains, and has potential applications in various reasoning tasks and future advancements in language model development..Use a detailed plain text question as input to the',\n",
       " 'how_we_scaled_support_without_slowing_down.md': 'Arize Copilot, an AI tool designed to streamline workflows and automate debugging, has scaled its support capabilities without slowing down by strategically partnering with AI-powered support solution, RunLLM. The partnership has allowed Arize to enhance technical support quickly, without diverting engineers from core development, and has resulted in a steady growth in Copilot adoption, with plans for further expansion and integration based on customer feedback..Use a detailed plain text question as input to the',\n",
       " 'unified_tool_for_evalution_and_observability.md': 'The blog post discusses the need for a unified tool for AI evaluation and observability, highlighting the Arize platform that bridges the gap between development and production phases in AI engineering. Arize provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types, enabling AI teams to develop, monitor, and iterate their applications with confidence, thereby ensuring high performance across diverse AI models..Use a detailed plain text question as input to the',\n",
       " 'agent_router_best_practices.md': 'The article discusses the importance of an AI agent router in managing user requests and routing them to the correct function within a system, particularly in large-scale conversational systems. It provides an overview of when to implement an agent router, different implementation approaches such as function calling, intent-based routing, and pure code routing, and best practices for agent router implementation including scope management, developing clear guidelines, and performance monitoring..Use a detailed plain text question as input to the',\n",
       " 'exploring_deepseek.md': \"DeepSeek is developing AI models that push the boundaries of reasoning and reinforcement learning, aiming to train AI to think more like a human. The company's latest models, DeepSeek R.1 and R.1.0, are making significant strides in inference speed and reasoning abilities, with potential applications in enterprise AI, privacy-focused AI, and traditional machine learning tasks..Use a detailed plain text question as input to the\",\n",
       " 'memory_and_state_in_llm_applications.md': 'The blog post discusses the concept of memory and state in Language Learning Model (LLM) applications, explaining how different approaches to memory management can impact performance, cost, and user experience. It also provides insights into various state management strategies, the importance of balancing memory usage, and how to choose the best strategy based on specific use cases..Use a detailed plain text question as input to the',\n",
       " 'how_to_build_an_ai_agent.md': 'The article provides a comprehensive guide on how to build an AI agent using three different frameworks: smolagents, AutoGen, and LangGraph. It explains the concept of an AI agent, when to use one, and how to implement it using these frameworks, with step-by-step instructions and code examples. The article also discusses the advantages and potential drawbacks of using a framework, and when to consider building an agent from scratch..Use a detailed plain text question as input to the'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_desc = json.dumps(descriptions, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"descriptions.json\", \"w\") as f:\n",
    "    f.write(json_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ReActAgent.from_tools(\n",
    "    tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_turns=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step eed86270-ead2-434d-90ac-f89a20ad5184. Step input: \n",
      "What tool should I use for AI quality?\n",
      "\n",
      "<hint> ALWAYS insert the URL to where you found the information in your response if you see it </hint>\n",
      "\n",
      "\u001b[1;3;38;5;200mThought: The user is asking about a tool for AI quality. This could refer to a tool for evaluating, monitoring, or improving the quality of AI models. The tool \"unified_tool_for_evalution_and_observability.md\" seems to be the most relevant as it discusses a platform for AI evaluation and observability. I will use this tool to find more information.\n",
      "Action: unified_tool_for_evalution_and_observability.md\n",
      "Action Input: {'input': 'What tool should I use for AI quality?'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: You should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models seamlessly. It also connects development and production in a single feedback loop, enabling faster iteration and confident deployment of AI applications.\n",
      "\u001b[0m> Running step 3f4f6c57-964f-4c30-a766-dd88ed60bc8b. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: You should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models seamlessly. It also connects development and production in a single feedback loop, enabling faster iteration and confident deployment of AI applications. You can learn more about it [here](https://arize.com/).\n",
      "\u001b[0mYou should consider using Arize. It's a unified AI observability and evaluation platform designed specifically for AI engineers. It provides end-to-end observability, evaluation, and troubleshooting capabilities across all AI model types. This allows you to develop, evaluate, monitor, and iterate your AI models seamlessly. It also connects development and production in a single feedback loop, enabling faster iteration and confident deployment of AI applications. You can learn more about it [here](https://arize.com/).\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What tool should I use for AI quality?\n",
    "\n",
    "<hint> ALWAYS insert the URL to where you found the information in your response if you see it </hint>\n",
    "\"\"\"\n",
    "\n",
    "response = agent.chat(prompt)\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {}\n",
    "for engine in engines:\n",
    "    with open(f\"./arize_blogs/{engine}\", \"r\") as f:\n",
    "        lines = f.read()\n",
    "    messages = [\n",
    "        ChatMessage(role=\"system\", content=\"\"\"You are a helpful assistant. Extract and return the title and URL to the source .md file.\n",
    "                    <hint> Always give answers in the form of\n",
    "                    Title: (title)\n",
    "                    URL: (url) </hint>\"\"\"),\n",
    "        ChatMessage(role=\"user\", content=lines),\n",
    "    ]\n",
    "    response = llm.chat(messages)\n",
    "    title = response.message.blocks[0].text.split(\"\\n\")[0].split(\": \")[1]\n",
    "    url = response.message.blocks[0].text.split(\"\\n\")[1].split(\": \")[1]\n",
    "\n",
    "    sources[engine] = {\"title\": title,\n",
    "                       \"url\": url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Agentic RAG http://arize.com/blog/understanding-agentic-rag/\n"
     ]
    }
   ],
   "source": [
    "response.message.blocks[0].text.split(\"\\n\")\n",
    "title = response.message.blocks[0].text.split(\"\\n\")[0].split(\": \")[1]\n",
    "url = response.message.blocks[0].text.split(\"\\n\")[1].split(\": \")[1]\n",
    "print(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': {'title': 'Understanding Agentic RAG',\n",
       "  'url': 'http://arize.com/blog/understanding-agentic-rag/'},\n",
       " 'multiagent_finetuning.md': {'title': 'Multiagent Finetuning',\n",
       "  'url': 'http://arize.com/blog/multiagent-finetuning-a-conversation-with-researcher-yilun-du/'},\n",
       " 'how_we_scaled_support_without_slowing_down.md': {'title': 'How We Scaled Support in Arize Copilot Without Slowing Down',\n",
       "  'url': 'http://arize.com/blog/how-we-scaled-support-in-arize-copilot-without-slowing-down/'},\n",
       " 'unified_tool_for_evalution_and_observability.md': {'title': 'Why AI Engineers Need a Unified Tool for AI Evaluation and Observability',\n",
       "  'url': 'http://arize.com/blog/why-ai-engineers-need-a-unified-tool-for-ai-evaluation-and-observability/'},\n",
       " 'agent_router_best_practices.md': {'title': 'Best Practices for Building an Agent Router',\n",
       "  'url': 'http://arize.com/blog/best-practices-for-building-an-ai-agent-router/'},\n",
       " 'exploring_deepseek.md': {'title': 'How DeepSeek is Pushing the Boundaries of AI Development',\n",
       "  'url': 'http://arize.com/blog/how-deepseek-is-pushing-the-boundaries-of-ai-development/'},\n",
       " 'memory_and_state_in_llm_applications.md': {'title': 'Memory and State in LLM Applications',\n",
       "  'url': 'http://arize.com/blog/memory-and-state-in-llm-applications/'},\n",
       " 'how_to_build_an_ai_agent.md': {'title': 'How to Build An AI Agent',\n",
       "  'url': 'http://arize.com/blog/how-to-build-an-ai-agent/'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_desc = json.dumps(sources, indent=4)\n",
    "with open(\"sources.json\", \"w\") as f:\n",
    "    f.write(json_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agentic_rag.md': {'title': 'Understanding Agentic RAG',\n",
       "  'url': 'http://arize.com/blog/understanding-agentic-rag/'},\n",
       " 'multiagent_finetuning.md': {'title': 'Multiagent Finetuning',\n",
       "  'url': 'http://arize.com/blog/multiagent-finetuning-a-conversation-with-researcher-yilun-du/'},\n",
       " 'how_we_scaled_support_without_slowing_down.md': {'title': 'How We Scaled Support in Arize Copilot Without Slowing Down',\n",
       "  'url': 'http://arize.com/blog/how-we-scaled-support-in-arize-copilot-without-slowing-down/'},\n",
       " 'unified_tool_for_evalution_and_observability.md': {'title': 'Why AI Engineers Need a Unified Tool for AI Evaluation and Observability',\n",
       "  'url': 'http://arize.com/blog/why-ai-engineers-need-a-unified-tool-for-ai-evaluation-and-observability/'},\n",
       " 'agent_router_best_practices.md': {'title': 'Best Practices for Building an Agent Router',\n",
       "  'url': 'http://arize.com/blog/best-practices-for-building-an-ai-agent-router/'},\n",
       " 'exploring_deepseek.md': {'title': 'How DeepSeek is Pushing the Boundaries of AI Development',\n",
       "  'url': 'http://arize.com/blog/how-deepseek-is-pushing-the-boundaries-of-ai-development/'},\n",
       " 'memory_and_state_in_llm_applications.md': {'title': 'Memory and State in LLM Applications',\n",
       "  'url': 'http://arize.com/blog/memory-and-state-in-llm-applications/'},\n",
       " 'how_to_build_an_ai_agent.md': {'title': 'How to Build An AI Agent',\n",
       "  'url': 'http://arize.com/blog/how-to-build-an-ai-agent/'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./sources.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Understanding Agentic RAG',\n",
       " 'url': 'http://arize.com/blog/understanding-agentic-rag/'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['agentic_rag.md']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ToolMetadata.__init__() got an unexpected keyword argument 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m     data = json.load(f)\n\u001b[32m      4\u001b[39m description = data[engine]\n\u001b[32m      5\u001b[39m qetool = QueryEngineTool(\n\u001b[32m      6\u001b[39m         query_engine = engines[engine],\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         metadata=\u001b[43mToolMetadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdescription\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUse a detailed plain text question as input to the\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: ToolMetadata.__init__() got an unexpected keyword argument 'title'"
     ]
    }
   ],
   "source": [
    "for engine in engines:\n",
    "    with open(\"descriptions.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    description = data[engine]\n",
    "    qetool = QueryEngineTool(\n",
    "            query_engine = engines[engine],\n",
    "            metadata=ToolMetadata(\n",
    "                name=engine,\n",
    "                description=(\n",
    "                    f\"{description}.\"\n",
    "                    \"Use a detailed plain text question as input to the\"\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
